## redshift -> snowflake
## syntax
`is True` | `is False` -> `= True` | `= False`

### docs
#### docs site
- the default overview page of the docs site can be changed
  - [changing docs default site (dbt forums)][3]
  - [s/o on changing the default overview][4]
##### Hosting Docs site
- [https://medium.com/dbt-local-taiwan/host-dbt-documentation-site-with-github-pages-in-5-minutes-7b80e8b62feb][5]
  
#### doc blocks

```python
{% docs user_id %}
The unique identifier for a user in the system. This value is consistent across all events and tables, providing a reliable way to join and analyze user data.
{% enddocs %}
```
#### doc block reference 
```python
models:
  - name: user_events
    description: |
      "Table containing events generated by users' activity."
    columns:
      - name: user_id
        description: "{{ doc('user_id') }}"
```

#### sample config block
**Common configs**
```python
{{ 
    config(
        # Materialization (e.g., 'view', 'table', 'incremental', 'ephemeral')
        materialized = 'table', 

        # Schema and alias configuration
        schema = 'analytics',                  # Custom schema for the model
        alias = 'custom_model_name',           # Custom table/view name in the database

        # Tags for organizing models
        tags = ['finance', 'etl'],             # Tags for metadata organization and filtering

        # Documentation persistence
        persist_docs = {                       # Enable documentation persistence for metadata
            "relation": true,                  # Persist docs at the table level
            "columns": true                    # Persist docs at the column level
        },

        # Incremental model settings
        unique_key = 'user_id',                # Unique key for merging rows in incremental models
        incremental_strategy = 'merge',       # Options: 'merge' or 'insert_overwrite'
        on_schema_change = 'sync_all_columns', # Options: 'ignore', 'fail', or 'sync_all_columns'

        # Query optimization
        enabled = true,                        # Whether the model is included in dbt runs
        full_refresh = false,                  # Force a full refresh for incremental models

        # Column-level configurations
        column_types = {                       # Override default column types
            "id": "bigint",
            "created_at": "timestamp"
        },

        # Post-hook and pre-hook SQL
        pre_hook = [
            "DELETE FROM analytics.temp_table WHERE id IS NOT NULL"
        ],
        post_hook = [
            "GRANT SELECT ON {{ this }} TO analytics_team"
        ],

        # Cluster and partitioning
        cluster_by = ['user_id', 'created_at'], # Clustering columns (e.g., for BigQuery, Snowflake)
        partition_by = {                       # Partitioning configurations
            "field": "created_at",             # Partition column
            "data_type": "date"                # Data type for partitioning (e.g., DATE, TIMESTAMP)
        },

        # Resource configurations
        grants = {                             # Access control settings
            "select": ["group:analytics_team"]
        },

        # Logging and query tagging
        query_tag = 'finance_pipeline',        # Add a tag to the query for tracking

        # Timeout settings
        timeout = 3600                         # Query execution timeout in seconds
    ) 
}}
```

There is small variance per database. See the database specific reference file in this folder.
- [bigquery](bigquery.md)
#### sample model blog

### regex
```python
import re
print (re.search('bush', 'BuSh', re.IGNORECASE))
print (re.match('bush', 'BuSh', re.IGNORECASE))
print (re.sub('bush', 'xxxx', 'Bushmeat', flags=re.IGNORECASE))
```
#### regex for combing dbt logs
```python
[\d*:].*success.*\]
```
for removing all success/start lines:
```python
.*(success|run).*\n
```
### dev macros/hacks
- [use a macro to limit read size during model builds][2]

### Related guides
- [Taking Your dbt CI Pipeline to the Next Level][1]
- [FAQ: I got an "unused model configurations" error message. What does this mean?][6]

[1]: https://www.datafold.com/blog/taking-your-dbt-ci-pipeline-to-the-next-level
[2]: https://github.com/dbt-labs/docs.getdbt.com/discussions/1334
[3]: https://discourse.getdbt.com/t/customizing-dbt-docs-website/3183/2
[4]: https://stackoverflow.com/questions/69191415/dbt-docs-generate-override-the-default-overview-page-with-custom-content-in-th
[5]: [https://medium.com/dbt-local-taiwan/host-dbt-documentation-site-with-github-pages-in-5-minutes-7b80e8b62feb]
[6]: https://discourse.getdbt.com/t/faq-i-got-an-unused-model-configurations-error-message-what-does-this-mean/112